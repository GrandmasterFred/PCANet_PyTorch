{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This file will implement the dataloder for the headlights\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# This one generates the .json file that lists all the image names and their corresponding make and model, as well as which subfolder they are from"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "COMPCAR_DATASET = \"E:\\compcars\\sv_data_fromZIP\\sv_data\\image\"\n",
    "MAKE_MODEL_FILE = \"E:\\compcars\\sv_data_fromZIP\\sv_data\\sv_make_model_name.mat\"\n",
    "JSON_OUTPUT = 'index_of_image_name_to_make_model.json'\n",
    "\n",
    "import scipy.io\n",
    "import os\n",
    "import json\n",
    "\n",
    "# getting the make and model whatever\n",
    "ann_labels = scipy.io.loadmat(MAKE_MODEL_FILE)\n",
    "ann_labels = ann_labels['sv_make_model_name']\n",
    "\n",
    "# looping through the images folder\n",
    "\n",
    "# Define the root folder\n",
    "root_folder = COMPCAR_DATASET\n",
    "\n",
    "# Initialize an empty list to store file information\n",
    "file_info_list = []\n",
    "\n",
    "# Walk through the directory tree\n",
    "for root, dirs, files in os.walk(root_folder):\n",
    "    for file_name in files:\n",
    "        # Get the full path of the file\n",
    "        file_path = os.path.join(root, file_name)\n",
    "\n",
    "        # Get the relative subfolder path (relative to the root folder)\n",
    "        relative_subfolder = os.path.relpath(root, root_folder)\n",
    "\n",
    "        # Add the file name and relative subfolder path to the list\n",
    "        # also get the make and model of it as well\n",
    "        make_model_temp = int(relative_subfolder) - 1\n",
    "        make_model_temp = ann_labels[make_model_temp]\n",
    "        label = []\n",
    "        for i in make_model_temp:\n",
    "            label.append(str(i[0]))\n",
    "        file_info_list.append({\n",
    "            'file_name': file_name,\n",
    "            'subfolder_path': relative_subfolder,\n",
    "            'make_model': label\n",
    "        })\n",
    "\n",
    "# now shove all of this into a folder,\n",
    "list_of_json = [json.dumps(item) for item in file_info_list]\n",
    "with open(JSON_OUTPUT, 'w') as json_file:\n",
    "    json.dump(list_of_json, json_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# loading it back into memory as a list of dictionaries\n",
    "import json\n",
    "\n",
    "JSON_OUTPUT = 'index_of_image_name_to_make_model.json'\n",
    "\n",
    "# loading json file into a list of dicionary\n",
    "with open(JSON_OUTPUT, 'r') as json_file:\n",
    "    loaded_json_strings = json.load(json_file)\n",
    "\n",
    "loaded_list_of_dicts = [json.loads(json_str) for json_str in loaded_json_strings]\n",
    "del loaded_json_strings     # just to clear it from memory"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# This will be the dataloader itself.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class HeadlightsCustomDataset(Dataset):\n",
    "    '''\n",
    "    this will be the headlight dataset\n",
    "    returns:\n",
    "        headlight image, of c, w, h\n",
    "        headlight labels, no need make and model, just subfolder number is enough\n",
    "    '''\n",
    "    def __init__(self, annotations_dir, img_dir, transform=None, target_transform=None, split=None):\n",
    "        import os\n",
    "        import scipy.io\n",
    "        self.annotations_dir = annotations_dir\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "        # count number of annotations there are, and then internalize it\n",
    "        if split is None:\n",
    "            # this means that there is no splitting of whatever, take up everything in the image dir\n",
    "            # this section would get the total number of images there are, all in the format of subfolder/image.jpg\n",
    "            self.ann_files = []\n",
    "            for root, _, files in os.walk(self.img_dir):\n",
    "                for file in files:\n",
    "                    relative_path = os.path.relpath(root, self.img_dir)\n",
    "                    file_path = os.path.join(relative_path, file)\n",
    "                    self.ann_files.append(file_path)\n",
    "        else:\n",
    "            # this one should just read the split file i guess\n",
    "            self.ann_files = split\n",
    "\n",
    "        # get the annotation names\n",
    "        self.ann_labels = scipy.io.loadmat(self.annotations_dir)\n",
    "        self.ann_labels = self.ann_labels['sv_make_model_name']         # this one should store the name as [N, 3] -> [make, model, web id]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ann_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # returns the annotations as well as the image needed\n",
    "        from torchvision.io import read_image\n",
    "\n",
    "        # this one gets the filepath of the image\n",
    "        short_file_path = self.ann_files[idx]              # this one only gives the subfolders i guess\n",
    "        temp_file_path = short_file_path\n",
    "        full_file_path = os.path.join(self.img_dir, short_file_path)\n",
    "\n",
    "        # figure out a way to parse out the subfolders\n",
    "        folders = []                                        # this should give [subfolder, image.jpg]\n",
    "        while True:\n",
    "            temp_file_path, folder = os.path.split(temp_file_path)\n",
    "            if folder != \"\":\n",
    "                folders.insert(0, folder)\n",
    "            else:\n",
    "                if temp_file_path != \"\":\n",
    "                    folders.insert(0, temp_file_path)\n",
    "                break\n",
    "\n",
    "        # utilize the subfolder to figure out the make and model of it. it should be folders[0]\n",
    "        # matching the subclass based on it\n",
    "        car_class = int(folders[0]) -1            # changing it to an integer just in case, and then making it sync up with elements\n",
    "        car_class = self.ann_labels[car_class]\n",
    "\n",
    "        # converting the car classes to tensor or list or whatever\n",
    "        label = []\n",
    "        for i in car_class:\n",
    "            label.append(str(i[0]))\n",
    "\n",
    "        # also adding in the name of the image as well\n",
    "        label.append(folders[-1])\n",
    "\n",
    "\n",
    "        # getting the image, and applying the transformations to it\n",
    "        image = read_image(full_file_path)\n",
    "\n",
    "        # transforming the image\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}