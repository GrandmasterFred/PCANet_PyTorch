from torch.utils.data import DataLoader, Dataset
import os
import torchvision.transforms.v2 as transforms
import torch
import torchvision
from torch.utils.data import DataLoader
import shutil
import random
import torch.nn.functional as F
import numpy as np
from sklearn.decomposition import IncrementalPCA
import torch.nn as nn
import math

def patch_mean_removal(patches):
    patches_mean = torch.mean(patches, dim=1, keepdim=True)
    patches = patches - patches_mean
    return patches

# function that takes in batches of images and then converts that into PCA filters
def batch_to_pca(batch_images, pca, filter_shape):
    batch_size = batch_images.shape[0]
    # TODOã€€for channel in channels:
    num_paddings = (filter_shape - 1) // 2     # (rawH - filter + 2*padding)/stride + 1 = processedH
    patches = F.unfold(batch_images, kernel_size=filter_shape, padding=num_paddings)
    patches = patches.reshape(batch_size, filter_shape * filter_shape, -1)
    patches = patch_mean_removal(patches)
    patch_matrix = patches.reshape(-1, filter_shape * filter_shape)
    #patch_matrix = patch_matrix.to(torch.device('cuda:0'))     # it seems like sklearn does not support cuda computing, which sucks, since it is forced to use cpus which is slow af
    patch_matrix = patch_matrix.cpu()               # this needs to be investigated to see if the matrix is getting passed correctly or not
    pca.partial_fit(patch_matrix)       # incrementally stores significant vectors

def pca_components_to_kernel(components, output_channel, filter_shape):
    eigenvectors = components.astype(np.float32)
    kernel = eigenvectors.reshape(output_channel, -1, filter_shape, filter_shape)
    return kernel


def generate_and_set_pca_broadcast_equal_int(current_feature, current_fmap, logger=None):
    """
    This is a modified method that broadcasts the weights instead. It should work as a drop in for the original method. This one additionally attempts to match the standard deviation and the mean of the weights so that the initialization does not go absolutely batshit crazy 

    Added logger support so that we can print magically as well 
    :param current_feature: which convolutional layer that should be modified right now.
    :param current_fmap: should be a tensor of shape N, Channel, Width, height
    :return:
    """

    # this one assumes that the logger is the one i use 
    def custom_print(message):
        try:
            if logger is None:
                print(message)
            else:
                logger.log(message)
        except Exception as e:
            print(e)
    
    # this function allows us to modify a given tensor to a target tensor
    def adjust_tensor(tensor, target_mean, target_std):
        # Calculate mean and standard deviation of the tensor
        current_mean = tensor.mean().item()
        current_std = tensor.std().item()

        # Adjust the tensor to match the target mean and standard deviation
        adjusted_tensor = (tensor - current_mean) * (target_std / current_std) + target_mean

        return adjusted_tensor

    # defines empty tensor to store the generated weights
    output_channel, _, _, filter_shape  = current_feature.weight.shape
    conv2_weight = np.zeros((current_feature.weight.shape))

    # this section does a check for the number of features that are able to be generated by this conv layer
    max_features = filter_shape * filter_shape
    needed_components = output_channel          # this one would dictate how the PCA eigenvectors are respared into the kernels

    custom_shape = False

    custom_print(f'target of shape {current_feature.weight.shape}, broadcasting method')

    # this one loops through each of the required channel, and then calculates the PCA for it. I probably need a catch clause to be able to extract the correct amount of PCA features. Since at higher filter counts, there would not be enough features to go around to fit all the kernels that we have
    for i in range(0, current_feature.weight.shape[1]):
        temp = current_fmap[:, i:i+1, :, :].clone()

        # this will then do the PCA calculations, and then collect all of them i guess
        if output_channel > max_features:
            # this means that the features cannot accomodate componenets, we just set the number of componenets to be maximum feature
            pca_increment_object = IncrementalPCA(n_components=max_features)
            #custom_print(f'smaller PCA, {max_features} of {output_channel}, broadcasting is used')
            needed_components = max_features
            custom_shape = True
        else:
            pca_increment_object = IncrementalPCA(n_components=output_channel)
            needed_components = output_channel
        # it seems like i have to iterate over this part so that my computer does not shit itself
        for small_batch in temp:
            batch_to_pca(small_batch, pca_increment_object, filter_shape)

        kernel = pca_components_to_kernel(pca_increment_object.components_, needed_components, filter_shape)        # this one is reshaped based on needed componeneets
        #print(f'{temp.shape}, and {kernel.shape}')

        # duplicating them, and then making sure that the weight fits 
        if custom_shape:
            # we will then have to add to the other components, so i shall generate them
            layers_needed = math.ceil(conv2_weight.shape[0]/kernel.shape[0])
            # print(layers_needed)
            duplicated_kernel = None
            for _ in range(0, layers_needed):
                # this section here concatenates the kernel over and over 
                if duplicated_kernel is None:
                    duplicated_kernel = kernel
                else:
                    duplicated_kernel = np.concatenate([duplicated_kernel, kernel], axis=0)
                # print(duplicated_kernel.shape)
            # this is the DUPLICATED generated kernel, just slicing it to the correct shape 
            conv2_weight[:, i:i+1, :, :] = duplicated_kernel[:conv2_weight.shape[0], :, :, :]
        else:
            # this is the default method of assigninig it
            conv2_weight[:, i:i+1, :, :] = kernel

    # i wonder if this sets it correctly into the model itself
    # setting the weights into the model
    temp1 = current_feature.weight.cuda()
    # i need to convert the weight here to floattensor
    #print(temp1)

    state_check = str(current_feature.state_dict())
    check1 = str(temp1[0, 0, 0, 0].item())
    custom_print(check1)

    if custom_shape:
        # this means that i have to be careful not to overwrite some weights with zeros, and let them keep the initalized values
        conv2_weight = torch.from_numpy(conv2_weight).to(torch.float).cuda()

        # this is the target weight  
        temp_storage = temp1.detach()

        # getting the mean and std div of target weight, meaning the original 
        target_mean_A = temp1.mean().item()
        target_std_A = temp1.std().item()

        custom_print(f'original mean is {target_mean_A}, original standard div is {target_std_A}')
        custom_print(f'generated mean is {conv2_weight.mean().item()}, generated standard div is {conv2_weight.std().item()}')

        # by adding the value with adjusted tensor, we get a final adjusted tensor? Does it work like this? 
        final_weight = temp_storage + conv2_weight

        # adjusting the stard div and mean of the generated weights 
        final_weight = adjust_tensor(final_weight, target_mean_A, target_std_A)
        
        custom_print(f'added together mean is {final_weight.mean().item()}, added together standard div is {final_weight.std().item()}')
        if torch.isnan(final_weight).any() or torch.isinf(final_weight).any():
            # Handle NaN or Inf values if necessary
            custom_print("Warning: NaN or Inf values detected in the final weight.")
        
        # finally setting in the weights 
        current_feature.weight = nn.Parameter(final_weight)
        #print(torch.eq(temp1, temp_storage))
    else:
        current_feature.weight = nn.Parameter(torch.from_numpy(conv2_weight).to(torch.float).cuda())

    check2 = str(current_feature.weight[0, 0, 0, 0].item())
    custom_print(check2)

    custom_print(f'they are the same? {state_check == str(current_feature.state_dict())}')




def generate_and_set_pca_broadcast(current_feature, current_fmap):
    """
    This is a modified method that broadcasts the weights instead. It should work as a drop in for the original method 
    :param current_feature: which convolutional layer that should be modified right now.
    :param current_fmap: should be a tensor of shape N, Channel, Width, height
    :return:
    """
    # defines empty tensor to store the generated weights
    output_channel, _, _, filter_shape  = current_feature.weight.shape
    conv2_weight = np.zeros((current_feature.weight.shape))

    # this section does a check for the number of features that are able to be generated by this conv layer
    max_features = filter_shape * filter_shape
    needed_components = output_channel          # this one would dictate how the PCA eigenvectors are respared into the kernels

    custom_shape = False

    print(f'target of shape {current_feature.weight.shape}, broadcasting method')

    # this one loops through each of the required channel, and then calculates the PCA for it. I probably need a catch clause to be able to extract the correct amount of PCA features. Since at higher filter counts, there would not be enough features to go around to fit all the kernels that we have
    for i in range(0, current_feature.weight.shape[1]):
        temp = current_fmap[:, i:i+1, :, :].clone()

        # this will then do the PCA calculations, and then collect all of them i guess
        if output_channel > max_features:
            # this means that the features cannot accomodate componenets, we just set the number of componenets to be maximum feature
            pca_increment_object = IncrementalPCA(n_components=max_features)
            print(f'smaller PCA, {max_features} of {output_channel}, broadcasting is used')
            needed_components = max_features
            custom_shape = True
        else:
            pca_increment_object = IncrementalPCA(n_components=output_channel)
            needed_components = output_channel
        # it seems like i have to iterate over this part so that my computer does not shit itself
        for small_batch in temp:
            batch_to_pca(small_batch, pca_increment_object, filter_shape)

        kernel = pca_components_to_kernel(pca_increment_object.components_, needed_components, filter_shape)        # this one is reshaped based on needed componeneets
        #print(f'{temp.shape}, and {kernel.shape}')

        # duplicating them, and then making sure that the weight fits 
        if custom_shape:
            # we will then have to add to the other components, so i shall generate them
            layers_needed = math.ceil(conv2_weight.shape[0]/kernel.shape[0])
            # print(layers_needed)
            duplicated_kernel = None
            for _ in range(0, layers_needed):
                # this section here concatenates the kernel over and over 
                if duplicated_kernel is None:
                    duplicated_kernel = kernel
                else:
                    duplicated_kernel = np.concatenate([duplicated_kernel, kernel], axis=0)
                # print(duplicated_kernel.shape)
            # this is the DUPLICATED generated kernel, just slicing it to the correct shape 
            conv2_weight[:, i:i+1, :, :] = duplicated_kernel[:conv2_weight.shape[0], :, :, :]
        else:
            # this is the default method of assigninig it
            conv2_weight[:, i:i+1, :, :] = kernel

    # i wonder if this sets it correctly into the model itself
    # setting the weights into the model
    temp1 = current_feature.weight.cuda()
    # i need to convert the weight here to floattensor
    #print(temp1)

    state_check = str(current_feature.state_dict())
    check1 = str(temp1[0, 0, 0, 0].item())
    print(check1)

    if custom_shape:
        # this means that i have to be careful not to overwrite some weights with zeros, and let them keep the initalized values
        conv2_weight = torch.from_numpy(conv2_weight).to(torch.float).cuda()

        temp_storage = temp1.detach()
        # temp_storage[conv2_weight != 0] = conv2_weight[conv2_weight != 0]
        temp_storage = temp_storage + conv2_weight
        current_feature.weight = nn.Parameter(temp_storage)
        #print(torch.eq(temp1, temp_storage))
    else:
        current_feature.weight = nn.Parameter(torch.from_numpy(conv2_weight).to(torch.float).cuda())

    check2 = str(current_feature.weight[0, 0, 0, 0].item())
    print(check2)

    print(f'they are the same? {state_check == str(current_feature.state_dict())}')


def generate_and_set_pca(current_feature, current_fmap):
    """
    :param current_feature: which convolutional layer that should be modified right now.
    :param current_fmap: should be a tensor of shape N, Channel, Width, height
    :return:
    """
    # defines empty tensor to store the generated weights
    output_channel, _, _, filter_shape  = current_feature.weight.shape
    conv2_weight = np.zeros((current_feature.weight.shape))

    # this section does a check for the number of features that are able to be generated by this conv layer
    max_features = filter_shape * filter_shape
    needed_components = output_channel          # this one would dictate how the PCA eigenvectors are respared into the kernels

    custom_shape = False

    print(f'target of shape {current_feature.weight.shape}')

    # this one loops through each of the required channel, and then calculates the PCA for it. I probably need a catch clause to be able to extract the correct amount of PCA features. Since at higher filter counts, there would not be enough features to go around to fit all the kernels that we have
    for i in range(0, current_feature.weight.shape[1]):
        temp = current_fmap[:, i:i+1, :, :].clone()

        # this will then do the PCA calculations, and then collect all of them i guess
        if output_channel > max_features:
            # this means that the features cannot accomodate componenets, we just set the number of componenets to be maximum feature
            pca_increment_object = IncrementalPCA(n_components=max_features)
            print(f'smaller PCA, {max_features} of {output_channel}')
            needed_components = max_features
            custom_shape = True
        else:
            pca_increment_object = IncrementalPCA(n_components=output_channel)
            needed_components = output_channel
        # it seems like i have to iterate over this part so that my computer does not shit itself
        for small_batch in temp:
            batch_to_pca(small_batch, pca_increment_object, filter_shape)

        kernel = pca_components_to_kernel(pca_increment_object.components_, needed_components, filter_shape)        # this one is reshaped based on needed componeneets
        #print(f'{temp.shape}, and {kernel.shape}')

        # assigning them to their correct positions
        if custom_shape:
            # here we will have to assign then kernels differently
            conv2_weight[:needed_components, i:i+1, :, :] = kernel
        else:
            # this is the default method of assigninig it
            conv2_weight[:, i:i+1, :, :] = kernel

    # i wonder if this sets it correctly into the model itself
    # setting the weights into the model
    temp1 = current_feature.weight.cuda()
    # i need to convert the weight here to floattensor
    #print(temp1)

    state_check = str(current_feature.state_dict())
    check1 = str(temp1[0, 0, 0, 0].item())
    print(check1)

    if custom_shape:
        # this means that i have to be careful not to overwrite some weights with zeros, and let them keep the initalized values
        conv2_weight = torch.from_numpy(conv2_weight).to(torch.float).cuda()

        temp_storage = temp1.detach()
        temp_storage[conv2_weight != 0] = conv2_weight[conv2_weight != 0]
        current_feature.weight = nn.Parameter(temp_storage)
        #print(torch.eq(temp1, temp_storage))
    else:
        current_feature.weight = nn.Parameter(torch.from_numpy(conv2_weight).to(torch.float).cuda())

    check2 = str(current_feature.weight[0, 0, 0, 0].item())
    print(check2)

    print(f'they are the same? {state_check == str(current_feature.state_dict())}')

def pca_sampler(RANDOM_SEED, FOLDER_OUTPUT_LOCATION, PCA_SAMPLES_PER_CLASS, DATASET_LOCATION, DEBUG = False):

    # checks if the file exists or not, if it does not, get ready to create the file
    if not os.path.exists(FOLDER_OUTPUT_LOCATION):
        # creates the dataloader and all that, and then generates the file
        # note that we do not need transformation in this case, since we just want to pull the images, and as such, we do not need to transform them into whatever classes is needed

        gen = torch.Generator()
        gen.manual_seed(RANDOM_SEED)

        transform_to_img = transforms.Compose([
            transforms.ToPILImage()
        ])          # this is to be used to convert the tensor back to image

        # i now have to program an edge case here where in case it breaks when it gets deployed to the server
        try:
            transform = transforms.Compose([
                transforms.ToImage(),
                transforms.ToDtype(torch.float32, scale=True)
            ])      # since we dont need any fancy transformation, but the dataloader requires it to be a tensor for it to batch correctly
        except Exception as e:
            print(f'transform did not assign correctly {e}')
            transform = transforms.Compose([
                transforms.ToTensor()#,
                #transforms.ToDtype(torch.float32, scale=True)
            ])      # this should be roughly equivalent as far as I can tell

        dataset = torchvision.datasets.ImageFolder(root=DATASET_LOCATION, transform=transform)

        # generate the testing dataset, i can chuck away the other two i guess
        # Create data loaders for training and validation
        batch_size = 1          # this is changed to 1 due to unequal size stacking of tensors
        train_size = int(0.8 * len(dataset))
        val_size = len(dataset) - train_size
        train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size], generator=gen)
        # split this up again for val and test dataset
        test_size = int(0.5 * len(val_dataset))
        val_size = len(val_dataset) - test_size
        val_dataset, test_dataset = torch.utils.data.random_split(val_dataset, [val_size, test_size], generator=gen)

        print('dataset is successeful')

        # initializaing the training loader, since it is the only one that is needed here
        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=batch_size)
        test_loader = DataLoader(test_dataset, batch_size=batch_size)

        # loop through the train dataloader, and save it all to the index provided. Note that this saves using the ImageFolder index, since I dont need to know which exact class it is, since afterall, we will just be sampling this for PCA anyways
        # i am generating it for val and testing as well, since I would like to get the index values of them as well for ImageFetch to check for different images i reckon
        for loader, name in zip([train_loader, val_loader, test_loader], ['train', 'val', 'test']):
            for idx, (image, label) in enumerate(loader):

                # saving function goes here
                # checking if output folder exists, and then generating it
                target_subfolder = os.path.join(FOLDER_OUTPUT_LOCATION, os.path.join(name, str(label.item())))

                if not os.path.exists(target_subfolder):
                    # create the folder
                    try:
                        os.makedirs(target_subfolder)
                    except Exception as e:
                        print(f'folder cant be created cause of {e}')

                # save the image to the folder
                pil_image = transform_to_img(image[0])      # i have to call the 0 item because remember, the data is batched, so it looks like batch, channel, width, height, calling it [0] converts it to channel, width, height
                filename = f'{str(idx)}.png'     # basicaly the index, so it can be called upon
                file_path = os.path.join(target_subfolder, filename)

                # print(file_path)
                pil_image.save(file_path)

    # this section happens after the checking/ creation of the test and validation set i guess. This section will select out random images for each class based on the number of samples requested. I guess I will return the directory of the folder that we used?
    pca_sampled_location = os.path.join(FOLDER_OUTPUT_LOCATION, f'{PCA_SAMPLES_PER_CLASS}_random_samples')

    # prepares the folder, just in case there is anything in it

    # Check if the folder exists
    if os.path.exists(pca_sampled_location):
        # Remove content inside the folder
        for filename in os.listdir(pca_sampled_location):
            file_path = os.path.join(pca_sampled_location, filename)
            try:
                if os.path.isfile(file_path) or os.path.islink(file_path):
                    os.unlink(file_path)
                elif os.path.isdir(file_path):
                    shutil.rmtree(file_path)
            except Exception as e:
                print(f"Error removing file or directory {file_path}: {e}")
    else:
        # Create the folder if it doesn't exist
        os.makedirs(pca_sampled_location)

    # extract samples fron the training split
    def copy_random_images(source_folder, target_folder, num_images_per_subfolder):
        # Iterate through subfolders in the source folder
        for subfolder in os.listdir(source_folder):
            subfolder_path = os.path.join(source_folder, subfolder)

            # Check if it's a directory
            if os.path.isdir(subfolder_path):
                # List all images in the subfolder
                images = [img for img in os.listdir(subfolder_path) if img.lower().endswith(('.png', '.jpg', '.jpeg'))]

                # Randomly select N images
                selected_images = random.sample(images, min(num_images_per_subfolder, len(images)))

                # Create a subfolder with the same name in the target folder
                target_subfolder = os.path.join(target_folder, subfolder)
                os.makedirs(target_subfolder, exist_ok=True)

                # Copy selected images to the target subfolder
                for img in selected_images:
                    source_path = os.path.join(subfolder_path, img)
                    target_path = os.path.join(target_subfolder, img)
                    shutil.copyfile(source_path, target_path)

    # this would be the folder that is created for the training set
    source_folder = target_subfolder = os.path.join(FOLDER_OUTPUT_LOCATION, 'train')
    copy_random_images(source_folder=source_folder, target_folder=pca_sampled_location, num_images_per_subfolder=PCA_SAMPLES_PER_CLASS)

    return pca_sampled_location